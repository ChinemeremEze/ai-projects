{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Simulation\n",
    "\n",
    "<strong>Autonomous Driving</strong> involves using sensors and algorithms to navigate a vehicle without human intervention. In simulations, reinforcement learning algorithms are often used.\n",
    "\n",
    "<h4>Key Steps:</h4>\n",
    "\n",
    "1. Simulation Environment: Set up an environment (e.g., CARLA, OpenAI Gym) to simulate driving.\n",
    "2. Model Training: Use reinforcement learning to train a model that can make driving decisions.\n",
    "3. Evaluation: Test the model in the simulation and improve its performance iteratively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Set up the simulation environment\n",
    "env = gym.make('CarRacing-v0')\n",
    "\n",
    "# Model architecture\n",
    "def build_model(input_shape, action_space):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(action_space, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "input_shape = (96, 96, 3)  # Example input shape\n",
    "action_space = env.action_space.shape[0]\n",
    "model = build_model(input_shape, action_space)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Training loop\n",
    "for episode in range(1000):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        state = np.array(state)\n",
    "        state = state.reshape(1, 96, 96, 3)  # Reshape for model input\n",
    "        action = model.predict(state)\n",
    "        next_state, reward, done, _ = env.step(action[0])  # env.step expects the action to be in a specific format\n",
    "        next_state = np.array(next_state)\n",
    "        next_state = next_state.reshape(1, 96, 96, 3)\n",
    "        \n",
    "        # Update model with new experience\n",
    "        target = reward + 0.95 * np.max(model.predict(next_state))  # Q-learning update\n",
    "        target_f = model.predict(state)\n",
    "        target_f[0][np.argmax(action)] = target\n",
    "        model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "# Visualize performance\n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    state = np.array(state)\n",
    "    state = state.reshape(1, 96, 96, 3)\n",
    "    action = model.predict(state)\n",
    "    state, reward, done, _ = env.step(action[0])\n",
    "    env.render()\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
